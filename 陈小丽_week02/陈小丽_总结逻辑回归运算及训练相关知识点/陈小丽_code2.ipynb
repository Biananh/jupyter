{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa90044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f5326b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.49430863,  1.74637561,  0.37942232, ...,  1.49279561,\n",
       "         -0.47302665, -1.23400809],\n",
       "        [-0.41733419,  0.42774628,  0.61622131, ...,  1.61901941,\n",
       "         -0.0604999 ,  0.32045092],\n",
       "        [-0.87454173,  0.8531419 , -1.44508413, ..., -1.04165145,\n",
       "          0.2779275 , -1.46737763],\n",
       "        ...,\n",
       "        [-0.43530022,  2.78353409, -2.24988711, ..., -0.75958963,\n",
       "         -1.969848  , -1.55427578],\n",
       "        [ 0.60251253, -0.55707016, -0.27394034, ...,  1.83854632,\n",
       "         -0.29306485, -0.04513232],\n",
       "        [ 0.86915456, -0.52771531,  0.08390339, ..., -0.3749316 ,\n",
       "          0.58064245,  0.16369468]]),\n",
       " array([1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "        1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=make_classification()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aefec3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.28722291 -0.64712156 -0.05629322 ...  0.97128763 -1.71578278\n",
      "   0.99551736]\n",
      " [ 2.1384301   0.36970826 -0.54484402 ... -1.13736731  1.45178158\n",
      "   0.82680136]\n",
      " [-1.18095778 -0.87158946  0.19903236 ... -0.85467144  0.95884315\n",
      "  -1.84672365]\n",
      " ...\n",
      " [-1.03193995 -0.16118024  0.32961672 ...  0.40843908 -0.01299947\n",
      "  -0.41366292]\n",
      " [-1.19043664 -0.39664182 -0.90956894 ...  2.03209763  1.92282604\n",
      "   0.63459899]\n",
      " [ 2.1476808  -0.96506383 -0.10439185 ...  1.06672888  0.22340279\n",
      "  -0.73702642]]\n",
      "[0 0 1 0 1 1 0 0 0 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 1 1 1 1 0 0 1 0\n",
      " 1 0 1 0 0 1 0 0 1 0 1 0 0 1 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 1 1 1 0 0 0 0 1\n",
      " 1 1 0 0 1 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 0 1 0 0 1 1]\n",
      "(100, 20)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "X,y=make_classification()\n",
    "print(X)\n",
    "print(y)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "722d82a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.38466608 -0.31623322  1.1991844  ...  1.98170516 -1.02994472\n",
      "  -2.13733645]\n",
      " [ 0.05437144 -0.32168856  1.23206148 ...  2.04349037 -0.25702061\n",
      "   0.19705015]\n",
      " [-1.51085378  1.71632484 -4.56792788 ...  1.72667783  0.76148705\n",
      "   0.24571499]\n",
      " ...\n",
      " [ 1.67780721 -0.31149526  1.20639437 ...  1.79684205 -0.77819417\n",
      "   0.4312918 ]\n",
      " [ 0.71792181 -0.0680844   0.24580605 ... -0.84388348 -0.69274486\n",
      "   0.54853005]\n",
      " [ 1.74541527  0.58703214 -1.71372794 ...  0.19748192  0.1533285\n",
      "  -0.64776454]]\n",
      "[1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0 1 1 0 1 1 1 1 0 0 1 1\n",
      " 0 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 1 0 0 0 1 0 0 0 0 1 0 1\n",
      " 1 0 1 0 1 0 1 1 0 1 0 1 1 0 1 1 1 0 0 1 0 1 0 1 0 1 1 1 0 0 0 0 1 1 1 0 0\n",
      " 1 0 1 1 0 0 1 1 0 0 0 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1\n",
      " 1 0]\n",
      "(150, 10)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "X,y=make_classification(n_samples=150,n_features=10)   #生成模型数据\n",
    "print(X)\n",
    "print(y)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "770e5c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification   #生成训练数据\n",
    "from sklearn.model_selection import train_test_split   #可同时生成两种不同的训练样本\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4da6502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成训练数据\n",
    "X,y = make_classification(n_samples=150, n_features=10)\n",
    "\n",
    "#局部样本训练模型（过拟合模型）（测试预测不好）\n",
    "#新样本数据模型表现不好（泛化能力差）\n",
    "\n",
    "# 使用40%数据做测试\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1ea839f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 10)\n",
      "(60, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81f2fd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification   #生成训练数据\n",
    "from sklearn.model_selection import train_test_split   #可同时生成两种不同的训练样本\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72cb4203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.生成训练数据\n",
    "X,y = make_classification(n_samples=150, n_features=10)\n",
    "\n",
    "#局部样本训练模型（过拟合模型）（测试预测不好）\n",
    "#新样本数据模型表现不好（泛化能力差）\n",
    "\n",
    "# 使用30%数据做测试\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57ff9a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#权重参数\n",
    "theta = np.random.randn(1,10)\n",
    "bias = 0\n",
    "# 超参数\n",
    "lr = 0.01\n",
    "epochs = 3000  # 训练次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7a95072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.模型计算参数\n",
    "def forward(x, theta, bias):\n",
    "    # 线性运算\n",
    "    z = np.dot(theta, x.T) + bias # shape (105,10)\n",
    "    # sigmoid  概率转换函数\n",
    "    y_hat = 1 / (1 + np.exp(-z))  # shape (105,10)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c747b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算损失函数\n",
    "def loss(y,y_hat):\n",
    "    e=1e-8   #防止y_hat计算结果为0，添加极小值\n",
    "    return -y * np.log(y_hat + e) - (1 - y) * np.log(1 - y_hat + e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "493aab49",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#计算梯度\n",
    "def calc_gradient(x,y,y_hat):\n",
    "    # 计算梯度\n",
    "    m = x.shape[-1]\n",
    "    # theta梯度计算\n",
    "    delta_theta = np.dot((y_hat - y), x) / m\n",
    "    # bias梯度计算\n",
    "    delta_bias = np.mean(y_hat - y)\n",
    "    # 返回梯度\n",
    "    return delta_theta, delta_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1937b11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.2698899684148823, acc: 0.580952380952381\n",
      "epoch: 100, loss: 0.09432695752737312, acc: 0.9904761904761905\n",
      "epoch: 200, loss: 0.06825486331789032, acc: 0.9809523809523809\n",
      "epoch: 300, loss: 0.05841169553483461, acc: 0.9904761904761905\n",
      "epoch: 400, loss: 0.05236019785257915, acc: 0.9904761904761905\n",
      "epoch: 500, loss: 0.04797560760028129, acc: 0.9904761904761905\n",
      "epoch: 600, loss: 0.044548239634034426, acc: 0.9904761904761905\n",
      "epoch: 700, loss: 0.04174929464670241, acc: 0.9904761904761905\n",
      "epoch: 800, loss: 0.03939627995810854, acc: 1.0\n",
      "epoch: 900, loss: 0.03737619562655056, acc: 1.0\n",
      "epoch: 1000, loss: 0.035613837572029176, acc: 1.0\n",
      "epoch: 1100, loss: 0.03405653132669183, acc: 1.0\n",
      "epoch: 1200, loss: 0.03266594056032895, acc: 1.0\n",
      "epoch: 1300, loss: 0.0314133126011619, acc: 1.0\n",
      "epoch: 1400, loss: 0.030276550369410602, acc: 1.0\n",
      "epoch: 1500, loss: 0.029238323749476554, acc: 1.0\n",
      "epoch: 1600, loss: 0.02828480524364749, acc: 1.0\n",
      "epoch: 1700, loss: 0.027404797176263217, acc: 1.0\n",
      "epoch: 1800, loss: 0.026589113407553752, acc: 1.0\n",
      "epoch: 1900, loss: 0.02583013152173051, acc: 1.0\n",
      "epoch: 2000, loss: 0.02512146217113171, acc: 1.0\n",
      "epoch: 2100, loss: 0.024457700748461205, acc: 1.0\n",
      "epoch: 2200, loss: 0.023834238056302713, acc: 1.0\n",
      "epoch: 2300, loss: 0.023247113995475993, acc: 1.0\n",
      "epoch: 2400, loss: 0.02269290311266388, acc: 1.0\n",
      "epoch: 2500, loss: 0.02216862407557181, acc: 1.0\n",
      "epoch: 2600, loss: 0.021671667348425953, acc: 1.0\n",
      "epoch: 2700, loss: 0.021199736872841615, acc: 1.0\n",
      "epoch: 2800, loss: 0.02075080264105392, acc: 1.0\n",
      "epoch: 2900, loss: 0.0203230618236309, acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "#模型训练\n",
    "for i in range(epochs):\n",
    "    # 前向计算\n",
    "    y_hat = forward(X_train, theta, bias)\n",
    "    # 计算损失\n",
    "    loss_val = loss(y_train, y_hat)\n",
    "    # 计算梯度\n",
    "    delta_theta, delta_bias = calc_gradient(X_train, y_train, y_hat)\n",
    "    # 更新参数\n",
    "    theta = theta - lr * delta_theta\n",
    "    bias = bias - lr * delta_bias\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        # 计算准确率\n",
    "        acc = np.mean(np.round(y_hat) == y_train)  # 得到0-1序列，并和y_train相对比，调用mean将所有true转换为1，false转换为0\n",
    "        print(f\"epoch: {i}, loss: {np.mean(loss_val)}, acc: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "008d2adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.数据准备、数据拆分、权重及超参数准备\n",
    "# 2.执行模型运算，代入模型的参数，将输入项转换为概率值；\n",
    "# 3.设计损失函数及梯度计算函数\n",
    "# 4.通过迭代执行前向运算，并计算损失值、梯度值，更新梯度值，结合准确值得到模型\n",
    "# 准确性和数据相关联"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79be2897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: 0, predict: [0.]\n"
     ]
    }
   ],
   "source": [
    "# 模型推理\n",
    "idx = np.random.randint(len(X_test)) # 随机选择一个测试样本索引\n",
    "x = X_test[idx]\n",
    "y = y_test[idx]\n",
    "\n",
    "predict = np.round(forward(x, theta, bias))   #预测结果\n",
    "print(f\"y: {y}, predict: {predict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3625ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
